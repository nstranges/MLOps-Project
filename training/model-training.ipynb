{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e74fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report, matthews_corrcoef)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37ce50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the model\n",
    "def train_model(X_train, y_train, X_test, y_test, feature_names, is_pca = False, grid_search=False):\n",
    "    # Initialize and fit the model\n",
    "    start_model = RandomForestClassifier(\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        n_estimators=200,\n",
    "        min_samples_leaf=2, \n",
    "        min_samples_split=10,\n",
    "        max_depth=10,\n",
    "        max_features=None,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "\n",
    "    if grid_search:\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2', None],\n",
    "        }\n",
    "\n",
    "        # Searching for the best tree parameters\n",
    "        grid_search = GridSearchCV(\n",
    "            start_model,\n",
    "            param_grid,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        print(\"best_params_ ----> Random Forest:\", best_params)\n",
    "        print(\"best_rf_model: \", best_model)\n",
    "    else:\n",
    "        best_model = start_model\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Test predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    metrics_rf = calculate_performance_metrics(y_test, y_pred)\n",
    "    print_performance_metrics(metrics_rf)\n",
    "    if not is_pca:\n",
    "        feature_importance(best_model, X_train, feature_names)\n",
    "    return best_model\n",
    "\n",
    "# Useful values for classification\n",
    "def calculate_performance_metrics(y_test, y_pred):\n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    metrics['precision'] = precision_score(y_test, y_pred, average='weighted')\n",
    "    metrics['recall'] = recall_score(y_test, y_pred, average='weighted')\n",
    "    metrics['f1_score'] = f1_score(y_test, y_pred, average='weighted')\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "    metrics['mcc'] = matthews_corrcoef(y_test, y_pred)\n",
    "    metrics['classification_report'] = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Prints all performance metrics\n",
    "def print_performance_metrics(metrics):\n",
    "    print(\"Accuracy:\", metrics.get('accuracy', \"Not computed\"))\n",
    "    print(\"Precision:\", metrics.get('precision', \"Not computed\"))\n",
    "    print(\"Recall:\", metrics.get('recall', \"Not computed\"))\n",
    "    print(\"F1 Score:\", metrics.get('f1_score', \"Not computed\"))\n",
    "    print(\"Confusion Matrix:\\n\", metrics.get('confusion_matrix', \"Not computed\"))\n",
    "    print(\"Matthews Correlation Coefficient (MCC):\", metrics.get('mcc', \"Not computed\"))\n",
    "    print(\"Classification Report:\\n\", metrics.get('classification_report', \"Not computed\"))\n",
    "\n",
    "# Determine the feature importance in the model\n",
    "def feature_importance(model, X, feature_names, should_print=True):\n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_importances_list = [(feature_names[j], importance) for j, importance in enumerate(feature_importances)]\n",
    "    feature_importances_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if should_print:\n",
    "        for feature, importance in feature_importances_list:\n",
    "            print(f\"{feature}: {importance}\")\n",
    "    return feature_importances_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b37816b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "def process_data(): \n",
    "    data_name = ''\n",
    "    processed_data = pd.read_csv(\"./data/final.csv\")\n",
    "    processed_data = processed_data.drop(columns=[\"date\"])\n",
    "\n",
    "\n",
    "    # Separate data\n",
    "    target_name = 'weather_code'\n",
    "    X = processed_data.drop(columns=[target_name]).values\n",
    "    y = processed_data[target_name].values\n",
    "\n",
    "    # feature_names = processed_data.columns[:-1].tolist()\n",
    "    feature_names = processed_data.drop(columns=[target_name]).columns.tolist()\n",
    "    return X,y,feature_names\n",
    "    \n",
    "\n",
    "# Trains the model\n",
    "def create_model():\n",
    "    X,y,feature_names = process_data()\n",
    "\n",
    "    # Get test and train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print('Read the data')\n",
    "    # Run the model\n",
    "    model = train_model(X_train, y_train, X_test, y_test, feature_names)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f0ded18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9131205673758865\n",
      "Precision: 0.9237610045960576\n",
      "Recall: 0.9131205673758865\n",
      "F1 Score: 0.9133527186854629\n",
      "Confusion Matrix:\n",
      " [[ 34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  44   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  26   5   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  12   1   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   2   2   0   4   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   3   0   0  11   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   6  13   2   0   0   0   0   2   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   3   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  30   8   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   9   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   3   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   2]]\n",
      "Matthews Correlation Coefficient (MCC): 0.8903361765923312\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        34\n",
      "         1.0       1.00      1.00      1.00        38\n",
      "         2.0       1.00      1.00      1.00        34\n",
      "         3.0       1.00      1.00      1.00       240\n",
      "        45.0       1.00      1.00      1.00        44\n",
      "        51.0       0.96      0.81      0.88        32\n",
      "        53.0       0.55      0.86      0.67        14\n",
      "        55.0       0.67      0.25      0.36         8\n",
      "        57.0       0.00      0.00      0.00         1\n",
      "        61.0       0.48      0.69      0.56        16\n",
      "        63.0       0.68      0.57      0.62        23\n",
      "        65.0       0.80      0.62      0.70        13\n",
      "        67.0       0.00      0.00      0.00         1\n",
      "        71.0       0.90      1.00      0.95         9\n",
      "        73.0       0.94      0.79      0.86        38\n",
      "        75.0       0.53      0.82      0.64        11\n",
      "        81.0       0.38      0.60      0.46         5\n",
      "        95.0       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.91       564\n",
      "   macro avg       0.72      0.70      0.69       564\n",
      "weighted avg       0.92      0.91      0.91       564\n",
      "\n",
      "cloud_cover_max: 0.18522489457852453\n",
      "precipitation_sum: 0.10213454934093937\n",
      "rain_sum: 0.07859552612789272\n",
      "snowfall_sum: 0.07795600440416504\n",
      "visibility_min: 0.07041849659912099\n",
      "snowfall_water_equivalent_sum: 0.06583885409291086\n",
      "cape_max: 0.06216559954614444\n",
      "soil_moisture_0_to_10cm_mean: 0.05422022045487333\n",
      "precipitation_hours: 0.04283252376813367\n",
      "cape_mean: 0.02831230264332025\n",
      "dew_point_2m_min: 0.024250238271728227\n",
      "dew_point_2m_max: 0.01828868243123826\n",
      "temperature_2m_min: 0.013262795809603873\n",
      "temperature_2m_max: 0.010102678370550733\n",
      "cloud_cover_mean: 0.007551958159734331\n",
      "surface_pressure_min: 0.006971596855806685\n",
      "dew_point_2m_mean: 0.006967605611744992\n",
      "wet_bulb_temperature_2m_min: 0.00648888251204915\n",
      "apparent_temperature_min: 0.006135179991851773\n",
      "wet_bulb_temperature_2m_max: 0.006126141897524818\n",
      "wind_gusts_10m_mean: 0.006124186286765192\n",
      "apparent_temperature_max: 0.005619907131809843\n",
      "day_of_year: 0.005051314819417564\n",
      "cloud_cover_min: 0.005006275968592862\n",
      "wind_gusts_10m_min: 0.004996350340334972\n",
      "pressure_msl_mean: 0.004564526635610013\n",
      "apparent_temperature_mean: 0.004528554264866061\n",
      "pressure_msl_min: 0.00433233652988236\n",
      "wind_speed_10m_max: 0.0042707070896135105\n",
      "vapour_pressure_deficit_max: 0.004135644831051074\n",
      "wind_direction_10m_dominant: 0.004089445354411409\n",
      "winddirection_10m_dominant: 0.0037468555678112636\n",
      "year_sin: 0.0036950845683082316\n",
      "pressure_msl_max: 0.0035936142363593294\n",
      "shortwave_radiation_sum: 0.00351133947785637\n",
      "surface_pressure_max: 0.0032976438204533306\n",
      "et0_fao_evapotranspiration: 0.0032625100729997123\n",
      "day_of_month: 0.0032334573251085984\n",
      "uv_index_max: 0.0030828053512199217\n",
      "wind_gusts_10m_max: 0.002952673707006974\n",
      "surface_pressure_mean: 0.0029382704640666165\n",
      "wind_speed_10m_mean: 0.002911075768189365\n",
      "visibility_max: 0.0028104396518410196\n",
      "sunshine_duration: 0.0027500363847704707\n",
      "year_cos: 0.0026213085630461654\n",
      "et0_fao_evapotranspiration_sum: 0.002549204380448814\n",
      "daylight_duration: 0.0024286900055014455\n",
      "temperature_2m_mean: 0.002423363168067817\n",
      "cape_min: 0.0024014754363903042\n",
      "relative_humidity_2m_mean: 0.002125802226189057\n",
      "relative_humidity_2m_max: 0.002105288072774983\n",
      "wet_bulb_temperature_2m_mean: 0.0020659648658954196\n",
      "wind_speed_10m_min: 0.0020659393223057603\n",
      "year: 0.001979220161163279\n",
      "day_of_week: 0.0019760366712371948\n",
      "relative_humidity_2m_min: 0.0018762153063538456\n",
      "visibility_mean: 0.0017873508207622022\n",
      "uv_index_clear_sky_max: 0.0013749253641906793\n",
      "month_sin: 0.0011796143799022258\n",
      "month: 0.00045072039951226604\n",
      "month_cos: 0.00023909374005447653\n",
      "showers_sum: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Runs the model\n",
    "def run_model_training():\n",
    "    # Train the model\n",
    "    model = create_model()\n",
    "    return model\n",
    "\n",
    "model = run_model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca2fe3a0-d24d-441d-939b-2c0e4f45d63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features to remove 24\n",
      "['uv_index_max', 'wind_gusts_10m_max', 'surface_pressure_mean', 'wind_speed_10m_mean', 'visibility_max', 'sunshine_duration', 'year_cos', 'et0_fao_evapotranspiration_sum', 'daylight_duration', 'temperature_2m_mean', 'cape_min', 'relative_humidity_2m_mean', 'relative_humidity_2m_max', 'wet_bulb_temperature_2m_mean', 'wind_speed_10m_min', 'year', 'day_of_week', 'relative_humidity_2m_min', 'visibility_mean', 'uv_index_clear_sky_max', 'month_sin', 'month', 'month_cos', 'showers_sum']\n",
      "Read the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.9279580856873649\n",
      "Recall: 0.9166666666666666\n",
      "F1 Score: 0.9174402048657891\n",
      "Confusion Matrix:\n",
      " [[ 34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0  44   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0  26   5   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   0  12   1   0   1   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   0   2   2   0   4   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   0   3   0   0  11   2   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   0   0   0   0   6  14   1   0   0   0   0   0   2\n",
      "    0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   3\n",
      "    0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  31   6   0\n",
      "    0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   9   0\n",
      "    0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   3\n",
      "    0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    2]]\n",
      "Matthews Correlation Coefficient (MCC): 0.8947701418112973\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        34\n",
      "         1.0       1.00      1.00      1.00        38\n",
      "         2.0       1.00      1.00      1.00        34\n",
      "         3.0       1.00      1.00      1.00       240\n",
      "        45.0       1.00      1.00      1.00        44\n",
      "        51.0       0.96      0.81      0.88        32\n",
      "        53.0       0.55      0.86      0.67        14\n",
      "        55.0       0.67      0.25      0.36         8\n",
      "        57.0       0.00      0.00      0.00         1\n",
      "        61.0       0.48      0.69      0.56        16\n",
      "        63.0       0.70      0.61      0.65        23\n",
      "        65.0       0.89      0.62      0.73        13\n",
      "        66.0       0.00      0.00      0.00         0\n",
      "        67.0       0.00      0.00      0.00         1\n",
      "        71.0       0.90      1.00      0.95         9\n",
      "        73.0       0.94      0.82      0.87        38\n",
      "        75.0       0.60      0.82      0.69        11\n",
      "        81.0       0.38      0.60      0.46         5\n",
      "        95.0       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.92       564\n",
      "   macro avg       0.69      0.67      0.66       564\n",
      "weighted avg       0.93      0.92      0.92       564\n",
      "\n",
      "cloud_cover_max: 0.18606988276667152\n",
      "precipitation_sum: 0.10442656180811744\n",
      "snowfall_sum: 0.08258794742414022\n",
      "rain_sum: 0.07824545084960823\n",
      "visibility_min: 0.07141897647354398\n",
      "cape_max: 0.0640232407415661\n",
      "snowfall_water_equivalent_sum: 0.06199907682320011\n",
      "soil_moisture_0_to_10cm_mean: 0.05513208403918849\n",
      "precipitation_hours: 0.045345936442524576\n",
      "cape_mean: 0.02957517777930374\n",
      "dew_point_2m_min: 0.025822954251962196\n",
      "dew_point_2m_max: 0.019254874702950266\n",
      "temperature_2m_min: 0.01513063166399758\n",
      "temperature_2m_max: 0.010899228948474659\n",
      "dew_point_2m_mean: 0.009350040563425966\n",
      "cloud_cover_mean: 0.008693677035300254\n",
      "wind_gusts_10m_mean: 0.008563210883082822\n",
      "et0_fao_evapotranspiration: 0.007626494025919277\n",
      "pressure_msl_mean: 0.007555278965788603\n",
      "wet_bulb_temperature_2m_max: 0.0071411096697328435\n",
      "day_of_year: 0.006698570812009977\n",
      "surface_pressure_min: 0.0066502673187404035\n",
      "apparent_temperature_min: 0.006529298939290493\n",
      "apparent_temperature_mean: 0.006527735554571507\n",
      "year_sin: 0.006445199091204465\n",
      "wet_bulb_temperature_2m_min: 0.006430693729173618\n",
      "wind_gusts_10m_min: 0.006424424966340775\n",
      "wind_speed_10m_max: 0.006411174402772503\n",
      "pressure_msl_min: 0.006058011777322449\n",
      "vapour_pressure_deficit_max: 0.005831221152406746\n",
      "apparent_temperature_max: 0.0056615187853350886\n",
      "shortwave_radiation_sum: 0.0054680957328343376\n",
      "cloud_cover_min: 0.005104047045660706\n",
      "winddirection_10m_dominant: 0.00508142273386429\n",
      "pressure_msl_max: 0.0042583345787238535\n",
      "day_of_month: 0.004170604759906987\n",
      "wind_direction_10m_dominant: 0.0038091874927571965\n",
      "surface_pressure_max: 0.0035783552685856855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def remove_features():\n",
    "    X,y,feature_names = process_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    importance_list = feature_importance(model, X_train, feature_names, False)\n",
    "    features_to_remove = []\n",
    "    total_importance = 0 \n",
    "    for feature, importance in importance_list:  \n",
    "        if total_importance >= 0.95:\n",
    "            features_to_remove.append(feature)\n",
    "        total_importance += importance\n",
    "            \n",
    "    \n",
    "    print(f\"Number of features to remove {len(features_to_remove)}\")\n",
    "    print(features_to_remove)\n",
    "    features_to_remove.append(\"date\")\n",
    "    return features_to_remove\n",
    "\n",
    "def run_model_reduced_data():\n",
    "    features_to_remove = remove_features()\n",
    "    \n",
    "    processed_data = pd.read_csv(\"./data/final.csv\")\n",
    "    processed_data = processed_data.drop(columns=features_to_remove)\n",
    "    \n",
    "    \n",
    "    # Separate data\n",
    "    target_name = 'weather_code'\n",
    "    X = processed_data.drop(columns=[target_name]).values\n",
    "    y = processed_data[target_name].values\n",
    "    \n",
    "    # feature_names = processed_data.columns[:-1].tolist()\n",
    "    feature_names = processed_data.drop(columns=[target_name]).columns.tolist()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print('Read the data')\n",
    "    new_model = train_model(X_train, y_train, X_test, y_test, feature_names)\n",
    "\n",
    "run_model_reduced_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b662984-ff5f-4975-9528-89bc1a4b0663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components to reach 95.0% variance: 19\n",
      "wind_direction_10m_dominant: 0.0172\n",
      "winddirection_10m_dominant: 0.0172\n",
      "day_of_week: 0.0172\n",
      "day_of_month: 0.0172\n",
      "apparent_temperature_mean: 0.0171\n",
      "dew_point_2m_mean: 0.0171\n",
      "wet_bulb_temperature_2m_mean: 0.0171\n",
      "temperature_2m_mean: 0.0171\n",
      "pressure_msl_mean: 0.0171\n",
      "surface_pressure_mean: 0.0171\n",
      "rain_sum: 0.0171\n",
      "precipitation_sum: 0.0170\n",
      "snowfall_water_equivalent_sum: 0.0170\n",
      "snowfall_sum: 0.0170\n",
      "apparent_temperature_max: 0.0169\n",
      "apparent_temperature_min: 0.0169\n",
      "wet_bulb_temperature_2m_min: 0.0169\n",
      "temperature_2m_max: 0.0169\n",
      "temperature_2m_min: 0.0169\n",
      "wet_bulb_temperature_2m_max: 0.0169\n",
      "year: 0.0168\n",
      "dew_point_2m_max: 0.0168\n",
      "dew_point_2m_min: 0.0168\n",
      "cape_min: 0.0168\n",
      "relative_humidity_2m_mean: 0.0166\n",
      "cape_mean: 0.0166\n",
      "wind_gusts_10m_mean: 0.0165\n",
      "cape_max: 0.0165\n",
      "et0_fao_evapotranspiration_sum: 0.0165\n",
      "et0_fao_evapotranspiration: 0.0165\n",
      "wind_speed_10m_mean: 0.0165\n",
      "day_of_year: 0.0164\n",
      "pressure_msl_max: 0.0164\n",
      "month: 0.0164\n",
      "surface_pressure_max: 0.0164\n",
      "visibility_mean: 0.0163\n",
      "soil_moisture_0_to_10cm_mean: 0.0163\n",
      "daylight_duration: 0.0163\n",
      "relative_humidity_2m_min: 0.0162\n",
      "year_cos: 0.0162\n",
      "surface_pressure_min: 0.0161\n",
      "pressure_msl_min: 0.0161\n",
      "month_cos: 0.0161\n",
      "visibility_max: 0.0161\n",
      "shortwave_radiation_sum: 0.0160\n",
      "wind_speed_10m_max: 0.0160\n",
      "wind_gusts_10m_min: 0.0159\n",
      "cloud_cover_max: 0.0159\n",
      "uv_index_clear_sky_max: 0.0159\n",
      "cloud_cover_min: 0.0159\n",
      "wind_gusts_10m_max: 0.0158\n",
      "wind_speed_10m_min: 0.0158\n",
      "year_sin: 0.0157\n",
      "uv_index_max: 0.0157\n",
      "vapour_pressure_deficit_max: 0.0156\n",
      "visibility_min: 0.0156\n",
      "month_sin: 0.0156\n",
      "cloud_cover_mean: 0.0154\n",
      "relative_humidity_2m_max: 0.0154\n",
      "sunshine_duration: 0.0148\n",
      "precipitation_hours: 0.0137\n",
      "showers_sum: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pca(): \n",
    "    X,y,feature_names = process_data()\n",
    "    # 1) Standardize features (very important for PCA if features have different scales)\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # 2) Fit PCA (keep all components to see the full curve)\n",
    "    pca = PCA(n_components=None, random_state=0)\n",
    "    X_pca = pca.fit_transform(X_std)\n",
    "    \n",
    "    # 3) Explained variance\n",
    "    evr = pca.explained_variance_ratio_             # per-component\n",
    "    cev = np.cumsum(evr)                            # cumulative\n",
    "    \n",
    "    # 4) Choose a target variance (e.g., 95%)\n",
    "    target = 0.95\n",
    "    k = np.argmax(cev >= target) + 1                # smallest k reaching target\n",
    "    \n",
    "    print(f\"Components to reach {target*100:.1f}% variance: {k}\")\n",
    "    \n",
    "    loadings = pca.components_\n",
    "    \n",
    "    # contributions of each feature across first k PCs\n",
    "    feature_contrib = np.sum((loadings[:k,:]**2).T * evr[:k], axis=1)\n",
    "    \n",
    "    # Normalize to 1\n",
    "    feature_contrib = feature_contrib / feature_contrib.sum()\n",
    "    \n",
    "    #realate variance the feature contribution\n",
    "    feature_importance = pd.Series(feature_contrib, index=feature_names)\n",
    "    # sort descending\n",
    "    feature_importance_sorted = feature_importance.sort_values(ascending=False)\n",
    "    \n",
    "    for feature, importance in feature_importance_sorted.items():\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "pca()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217c995-3c1e-445f-b661-ff4a724afb21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
